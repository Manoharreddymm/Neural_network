# -*- coding: utf-8 -*-
"""autoencoders.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1Fd9jho4c93CnkIRu_mu1vhbZtqgw_B5-
"""

import numpy as np
import matplotlib.pyplot as plt
from tensorflow.keras.layers import Input, Dense, Conv2D, MaxPooling2D, UpSampling2D
from tensorflow.keras.datasets import mnist
from tensorflow.keras.models import Sequential

#importing the data and normalizing the  data
(x_train,y_train),(x_test,y_test)=mnist.load_data()
x_train=x_train.astype('float32')/255.
x_test=x_test.astype('float32')/255.

x_train.shape

y_train

x_test.shape

y_test.shape

"""In deep learning, especially with convolutional neural networks (CNNs),
 it's common to use the 3D format even for single-channel images to maintain consistency in data handling and processing"""
x_train=np.reshape(x_train,(len(x_train),28,28,1))
x_test=np.reshape(x_test,(len(x_test),28,28,1))

#model treat input as image enables cnn to capture patterns like edge and texture detection
x_train.shape

x_test.shape

#Building an autoencoder
#encoder using Functional API

input_img=Input(shape=(28,28,1))
x=Conv2D(16,(3,3),activation='relu', padding='same')(input_img)
x=MaxPooling2D((2,2), padding='same')(x)
x=Conv2D(8,(3,3),activation='relu', padding='same')(x)
encoded=MaxPooling2D((2,2), padding='same')(x)

#decoder
x=Conv2D(8,(3,3),activation='relu', padding='same')(encoded)
x=UpSampling2D((2,2))(x)
x=Conv2D(16,(3,3),activation='relu', padding='same')(x)
x=UpSampling2D((2,2))(x)
decoded=Conv2D(1,(3,3),activation='sigmoid', padding='same')(x)

#autoencoder model
autoencoder=Model(input_img,decoded)
autoencoder.compile(optimizer='adam',loss='binary_crossentropy')

autoencoder.summary()

autoencoder.fit(
    x_train, x_train,  # Autoencoders use the same data for input and output
    epochs=10,
    batch_size=256,
    validation_data=(x_test, x_test)
)

# Display original and reconstructed images
decoded_imgs = autoencoder.predict(x_test)
n = 10  # Number of images to display
plt.figure(figsize=(20, 4))
for i in range(n):
    # Display original
    ax = plt.subplot(2, n, i + 1)
    plt.imshow(x_test[i].reshape(28, 28), cmap='gray')
    plt.title("Original")
    plt.axis("off")

    # Display reconstructed
    ax = plt.subplot(2, n, i + n + 1)
    plt.imshow(decoded_imgs[i].reshape(28, 28), cmap='gray')
    plt.title("Reconstructed")
    plt.axis("off")
plt.show()

# CNN Model on Reconstructed Images
# Reshape the data for the CNN input
reconstructed_imgs = decoded_imgs.reshape(-1, 28, 28, 1)

# Prepare CNN labels (same as original labels)
from tensorflow.keras.utils import to_categorical
y_train_categorical = to_categorical(y_train, num_classes=10)
y_test_categorical = to_categorical(y_test, num_classes=10)

# Build CNN Model
from tensorflow.keras.layers import Flatten, Dense, Dropout
from tensorflow.keras.models import Model
cnn_input = Input(shape=(28, 28, 1))
x = Conv2D(32, (3, 3), activation='relu', padding='same')(cnn_input)
x = MaxPooling2D((2, 2))(x)
x = Conv2D(64, (3, 3), activation='relu', padding='same')(x)
x = MaxPooling2D((2, 2))(x)
x = Flatten()(x)
x = Dense(128, activation='relu')(x)
x = Dropout(0.5)(x)
cnn_output = Dense(10, activation='softmax')(x)

cnn_model = Model(cnn_input, cnn_output)
cnn_model.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['accuracy'])

# Train the CNN on the reconstructed images
cnn_model.fit(reconstructed_imgs, y_test_categorical,
               epochs=10,
               batch_size=10,
               validation_split=0.2)

# Evaluate the CNN on the test set
test_loss, test_accuracy = cnn_model.evaluate(reconstructed_imgs, y_test_categorical)
print(f"Test loss: {test_loss}, Test accuracy: {test_accuracy}")

new_image = x_test[0]
new_image = np.reshape(new_image, (1, 28, 28, 1))
# Step 1: Encode and decode the new image using the autoencoder
reconstructed_image = autoencoder.predict(new_image)

# Step 2: Predict the class using the CNN model
predicted_class = cnn_model.predict(reconstructed_image)
predicted_label = np.argmax(predicted_class)  # Get the class label with the highest probability

# Display the new image, reconstructed image, and predicted label
plt.figure(figsize=(8, 4))

# Display original image
plt.subplot(1, 3, 1)
plt.imshow(new_image.reshape(28, 28), cmap='gray')
plt.title("Original Image")
plt.axis('off')

# Display reconstructed image
plt.subplot(1, 3, 2)
plt.imshow(reconstructed_image.reshape(28, 28), cmap='gray')
plt.title("Reconstructed Image")
plt.axis('off')

# Display predicted label
plt.subplot(1, 3, 3)
plt.text(0.5, 0.5, f'Predicted Label: {predicted_label}', fontsize=18, ha='center')
plt.axis('off')

plt.show()

import numpy as np

# Assume you have a new image; here we use a sample from the test set for demonstration.
new_image = x_test[1]  # Taking the first image from test set as a new input
new_image = np.reshape(new_image, (1, 28, 28, 1))  # Reshape to match input shape for the model

# Step 1: Encode and decode the new image using the autoencoder
reconstructed_image = autoencoder.predict(new_image)

# Step 2: Predict the class using the CNN model
predicted_class = cnn_model.predict(reconstructed_image)
predicted_label = np.argmax(predicted_class)  # Get the class label with the highest probability

# Print the predicted label
print(f'Predicted Label: {predicted_label}')