# -*- coding: utf-8 -*-
"""cnn.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1ASyH7Pp8bxOpkiMqwaDaJwuaNW-dxt3i
"""

import os
import shutil
from sklearn.model_selection import train_test_split

# Define paths to the original folders containing images of cats and dogs
cats_folder = '/content/drive/MyDrive/archive (9)/animals/cat'
dogs_folder = '/content/drive/MyDrive/archive (9)/animals/dog'
base_folder = '/content/drive/MyDrive/archive (9)/animals/test&train'

# Paths for train and test folders (they will be created if they don't exist)
train_folder = os.path.join(base_folder, 'train')
test_folder = os.path.join(base_folder, 'test')

# Create directories for train and test splits
os.makedirs(os.path.join(train_folder, 'cats'), exist_ok=True)
os.makedirs(os.path.join(train_folder, 'dogs'), exist_ok=True)
os.makedirs(os.path.join(test_folder, 'cats'), exist_ok=True)
os.makedirs(os.path.join(test_folder, 'dogs'), exist_ok=True)

# Function to split and copy files
def split_and_copy(source_folder, category):
    # List all images in the source folder
    images = os.listdir(source_folder)
    images = [img for img in images if img.endswith(('.png', '.jpg', '.jpeg'))]  # Filter for image files only

    # Check if images list is empty
    if not images:
        print(f"No images found in {source_folder}. Skipping this folder.")
        return

    # Split images into 80% train and 20% test
    train_images, test_images = train_test_split(images, test_size=0.3, random_state=11)

    # Copy images to the train and test folders
    for img in train_images:
        shutil.copy(os.path.join(source_folder, img), os.path.join(train_folder, category, img))

    for img in test_images:
        shutil.copy(os.path.join(source_folder, img), os.path.join(test_folder, category, img))

# Split and copy data for both categories
split_and_copy(cats_folder, 'cats')
split_and_copy(dogs_folder, 'dogs')

print("Data has been split into training and testing sets.")

#we are using the imaages so we are taking convnet 2D
#importing the required libraries
from tensorflow.keras.models import Sequential
from tensorflow.keras.layers import Conv2D, MaxPooling2D, Flatten, Dense

from PIL import Image

# Load the image
image_path = '/content/drive/MyDrive/archive (9)/animals/test&train/test/cats/00001-4122619874.png'
image = Image.open(image_path)

# Get the size of the image
width, height = image.size

print(f"Image Size: {width}x{height} pixels")

from tensorflow.keras.preprocessing.image import ImageDataGenerator
train_data=ImageDataGenerator(
    rescale=1./255,
    shear_range=0.2,
    zoom_range=0.2,
    horizontal_flip=True
)
test_data=ImageDataGenerator(
    rescale=1./255
)

train_set=train_data.flow_from_directory(
    '/content/drive/MyDrive/archive (9)/animals/test&train/train',
    target_size=(224,224),
    batch_size=10,
    class_mode='binary'
)

test_set=train_data.flow_from_directory(
    '/content/drive/MyDrive/archive (9)/animals/test&train/test',
    target_size=(224,224),
    batch_size=10,
    class_mode='binary'
)

model=Sequential()

model.add(Conv2D(32,(3,3),activation='relu',input_shape=(224,224,3)))
model.add(MaxPooling2D(pool_size=(2,2)))

model.add(Conv2D(16,(3,3),activation='relu'))
model.add(MaxPooling2D(pool_size=(2,2)))

model.add(Conv2D(32,(3,3),activation='relu'))
model.add(MaxPooling2D(pool_size=(2,2)))

model.add(Flatten())

#fully connected layer
model.add(Dense(128,activation='relu'))
model.add(Dense(1,activation='sigmoid'))

model.compile(optimizer='adam',loss='binary_crossentropy',metrics=['accuracy'])

model.summary()

model.fit(
    train_set,
    steps_per_epoch=748,
    epochs=3,
    validation_data=test_set,
    validation_steps=356
)

import numpy as np
from tensorflow.keras.preprocessing import image
test_image1=image.load_img('/content/drive/MyDrive/archive (9)/animals/cat/00000-4122619873.png',target_size=(224,224))#cat
test_image2=image.load_img('/content/drive/MyDrive/archive (9)/animals/dog/00500-3846168662.png',target_size=(224,224))#dog

test_image1=image.img_to_array(test_image1)

test_image1.shape

test_image1

test_image1=np.expand_dims(test_image1,axis=0)

test_image1.shape

test_image1

result=model.predict(test_image1)

train_set.class_indices

result

test_image2=image.img_to_array(test_image2)

test_image2=np.expand_dims(test_image2,axis=0)

result1=model.predict(test_image2)

result1