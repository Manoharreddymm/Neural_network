# -*- coding: utf-8 -*-
"""ANN.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1Wm4Z5B7ydXuTt_i8K7F_vl-trZ1QV7SQ
"""

import pandas as pd
import numpy as np
df=pd.read_csv('/content/drive/MyDrive/titanic.csv')
df.head()

#Data preprocessing
df.columns

df.drop(['PassengerId','Name','Ticket','Cabin'],axis=1,inplace=True)
df.head()

df['Embarked'].unique()

df.isnull().sum()

df['Age'].fillna(df['Age'].mean(),inplace=True)

df.isnull().sum()

df.dropna(inplace=True)

df.isnull().sum()

df['Embarked'].unique()

df= pd.get_dummies(df, columns=['Sex'])

df.head()

df= pd.get_dummies(df, columns=['Embarked'])

df.head()

df[['sex_female', 'sex_male','Embarked_c','Embarked_q','Embarked_s']] = df[['Sex_female', 'Sex_male','Embarked_C','Embarked_Q','Embarked_S']].astype(int)

df.head()

df.drop(['Sex_female', 'Sex_male','Embarked_C','Embarked_Q','Embarked_S'],axis=1,inplace=True)

df.head()

#scaling the data
from sklearn.preprocessing import StandardScaler
sc=StandardScaler()
data=sc.fit_transform(df)

data

data=pd.DataFrame(data=data,columns=df.columns)

data.head()

x=data.drop('Survived',axis=1)
y=df['Survived']

y

from sklearn.model_selection import train_test_split
x_train,x_test,y_train,y_test=train_test_split(x,y,test_size=0.2,random_state=42)

#creating a neural network
from tensorflow.keras.models import Sequential
from tensorflow.keras.layers import Dense
model=Sequential()
#input layer
model.add(Dense(64,input_shape=(10,),activation='relu'))
#hidden layers
model.add(Dense(64,activation='relu'))
model.add(Dense(32,activation='relu'))
#outputlayer(we can use softmax for multiclass classificatio)
model.add(Dense(1,activation='sigmoid'))

#parm- total number of trainable parameters in each layer
model.summary()

#compiling the data
model.compile(optimizer='adam',loss='BinaryCrossentropy',metrics=['accuracy'])

model.fit(x_train,y_train,epochs=20,batch_size=10)

# Evaluate the model
loss, accuracy = model.evaluate(x_test, y_test)
print(f"Test Loss: {loss:.4f}, Test Accuracy: {accuracy:.4f}")

# After training the model
y_pred = model.predict(x_test)  # Get predicted probabilities
y_pred_binary = (y_pred > 0.5).astype(int)
y_test_binary = (y_test > 0.5).astype(int)  # Convert to binary predictions
# Print predicted values
print("Predicted classes:", y_pred_binary.flatten())

from sklearn.metrics import confusion_matrix
cm=confusion_matrix(y_test_binary,y_pred_binary)
cm

y_train

!pip install scikeras

y_trainb

import numpy as np
import pandas as pd
from scikeras.wrappers import KerasClassifier
from sklearn.model_selection import GridSearchCV
from tensorflow.keras.models import Sequential
from tensorflow.keras.layers import Dense
from sklearn.preprocessing import StandardScaler
from sklearn.model_selection import train_test_split
from sklearn.datasets import make_classification

# Split the dataset into training and testing sets
X_train, X_test, y_train, y_test = train_test_split(x, y, test_size=0.2, random_state=42)

# Scale the features
scaler = StandardScaler()
X_train = scaler.fit_transform(X_train)
X_test = scaler.transform(X_test)

# Define a function to create the Keras model
def create_model(num_layers=1, num_neurons=1, optimizer='adam', activation='relu'):
    model = Sequential()
    model.add(Dense(num_neurons, input_dim=X_train.shape[1], activation=activation))
    for _ in range(num_layers - 1):
        model.add(Dense(num_neurons, activation=activation))
    model.add(Dense(1, activation='sigmoid'))  # Output layer for binary classification
    model.compile(loss='binary_crossentropy', optimizer=optimizer, metrics=['accuracy'])
    return model

# Create KerasClassifier
model = KerasClassifier(model=create_model, verbose=0)

# Set up the hyperparameter grid
param_grid = {
    'model__num_layers': [1, 2, 3],
    'model__num_neurons': [5, 10, 20],
    'batch_size': [10, 20],
    'optimizer': ['adam', 'rmsprop'],
    'model__activation': ['relu', 'tanh'],
    'epochs': [10, 20]
}

# Set up GridSearchCV
grid = GridSearchCV(estimator=model, param_grid=param_grid, cv=3)

# Fit the model with binary labels
grid_result = grid.fit(X_train, y_train)

# Summarize the results
print(f"Best: {grid_result.best_score_} using {grid_result.best_params_}")





